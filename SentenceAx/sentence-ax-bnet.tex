\documentclass[12pt]{article}
\input{bayesuvius.sty}
\begin{document}

\begin{figure}[h!]\centering
$$\xymatrix@R=1.5pc@C=3.5pc{
&&&&
\\
&&&&
\\
&&&&
\\
*+[F*:SkyBlue]{\underline{L}^{[86], [6]}}&*+[F*:pink]{\underline{S}^{[86], [768]}}\ar[uuu]\ar[uuul]\ar[uuur]\ar[uuurr]\ar[l]_{W_{il}}&&&
\\
&&*+[F*:pink]{\underline{E}^{[86], [768]}}\ar[ul]^{1}&*+[F*:yellow]{\underline{a}^{[86]}}\ar[l]&
\\
&&*+[F*:pink]{\underline{G}^{[86], [768]}}\ar[ur]&&
\\
&&*+[F*:Orchid]{\underline{n}^{[121], [768]}}\ar[u]&&
\\
&&*+[F*:Dandelion]{\underline{A}^{[121], [D]}}\ar[u]_{W_\rva}&&
\\
&*+[F*:Dandelion]{\underline{V}^{[121], [D]}}\ar[ur]&*+[F*:Dandelion]{\underline{K}^{[121], [D]}}\ar[u]&*+[F*:Dandelion]{\underline{Q}^{[121], [D]}}\ar[ul]&
\\
&&&&
\\
&&*+[F*:Orchid]{\underline{B}^{[121], [768]}}\ar[uu]|-{W_\rvk}\ar[uur]|-{W_\rvq}\ar[uul]|-{W_\rvv}&&
\\
&*+[F*:pink]{\underline{X}^{[86], [768]}}\ar[uuur]\ar[uuurr]\ar@/^6pc/[uuuuuuuu]^{1}\ar[uuu]&&&
\save
\POS"4,2"."9,2"."4,4"."9,4"!C*+<2em>\frm{-,}
\POS"7,2"."9,2"."7,4"."9,4"!C*+<1.3em>\frm{--}
\restore
}$$
\caption{SentenceAx Bayesian network. 2 copies of dashed box are connected in series. 5 copies of plain box are connected in series. We display the tensor shape superscripts in the Linear Algebra R2L order. (PyTorch uses a L2R order instead). All tensor shape superscripts have been simplified by omitting a $[s_{ba}]$, where $s_{ba}=24$ is the batch size. $D= d n_\rvh$ where $d=768$ is the hidden dimension per head, and $n_\rvh=12$ is the number of heads. }
\label{fig-texnn-for-sentence-ax-bnet}
\end{figure}

\begin{tabular}{ll}
$\underline{a}^{[86]}$ :&{\tt ll\_greedy\_ilabel}\\
$\underline{B}^{[121], [768]}$ :&{\tt lll\_hidstate}\\
$\underline{E}^{[86], [768]}$ :&{\tt lll\_pred\_code}\\
$\underline{G}^{[86], [768]}$ :&{\tt lll\_word\_hidstate}\\
$\underline{L}^{[86], [6]}$ :&{\tt lll\_word\_score}\\
$\underline{n}^{[121], [768]}$ :&{\tt lll\_hidstate}\\
$\underline{S}^{[86], [768]}$ :&{\tt lll\_word\_hidstate}\\
$\underline{X}^{[86], [768]}$ :&{\tt lll\_hidstate}
\end{tabular}



\begin{subequations}

\begin{equation}\color{blue}
A^{[121], [D]} = \text{Attention}(Q^{[121], [D]},K^{[121], [D]},V^{[121], [D]})
\label{eq-A-fun-sentence-ax-bnet}
\end{equation}

\begin{equation}\color{blue}
\begin{aligned}
a^{[86]} &= \text{argmax}(G^{[86], [768]};dim=-1)
\label{eq-a-fun-sentence-ax-bnet}
\\ &:{\tt ll\_greedy\_ilabel}
\end{aligned}
\end{equation}

\begin{equation}\color{blue}
\begin{aligned}
B^{[121], [768]} &= \text{BERT}()
\label{eq-B-fun-sentence-ax-bnet}
\\ &:{\tt lll\_hidstate}
\end{aligned}
\end{equation}

\begin{equation}\color{blue}
\begin{aligned}
E^{[86], [768]} &= \text{embedding}(a^{[86]})
\label{eq-E-fun-sentence-ax-bnet}
\\ &:{\tt lll\_pred\_code}
\end{aligned}
\end{equation}

\begin{equation}\color{blue}
\begin{aligned}
G^{[86], [768]} &= \text{gather}(n^{[121], [768]})
\label{eq-G-fun-sentence-ax-bnet}
\\ &:{\tt lll\_word\_hidstate}
\end{aligned}
\end{equation}

\begin{equation}\color{blue}
K^{[121], [D]} = (X^{[86], [768]}+B^{[121], [768]})W_\rvk^{[768], [D]}
\label{eq-K-fun-sentence-ax-bnet}
\end{equation}

\begin{equation}\color{blue}
\begin{aligned}
L^{[86], [6]} &= "M"W_{il}^{[300],[6]}
\label{eq-L-fun-sentence-ax-bnet}
\\ &:{\tt lll\_word\_score}
\end{aligned}
\end{equation}

\begin{equation}\color{blue}
\begin{aligned}
n^{[121], [768]} &= A^{[121], [D]}W_\rva^{[D], [768]}
\label{eq-n-fun-sentence-ax-bnet}
\\ &:{\tt lll\_hidstate}
\end{aligned}
\end{equation}

\begin{equation}\color{blue}
Q^{[121], [D]} = (X^{[86], [768]} + B^{[121], [768]})W_\rvq^{[768], [D]}
\label{eq-Q-fun-sentence-ax-bnet}
\end{equation}

\begin{equation}\color{blue}
\begin{aligned}
S^{[86], [768]} &= X^{[86], [768]} + E^{[86], [768]}
\label{eq-S-fun-sentence-ax-bnet}
\\ &:{\tt lll\_word\_hidstate}
\end{aligned}
\end{equation}

\begin{equation}\color{blue}
V^{[121], [D]} = (X^{[86], [768]} + B^{[121], [768]})W_\rvv^{[768], [D]}
\label{eq-V-fun-sentence-ax-bnet}
\end{equation}

\begin{equation}\color{blue}
\begin{aligned}
X^{[86], [768]} &= S^{[86], [768]}\;\;\text{( initially zero) }
\label{eq-X-fun-sentence-ax-bnet}
\\ &:{\tt lll\_hidstate}
\end{aligned}
\end{equation}

\end{subequations}


\end{document}  
